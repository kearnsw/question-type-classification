{"dataset_reader": {
        "type": "gard",
        "tokenizer": {
            "type": "word",
            "end_tokens": [
                "@@PADDING@@",
                "@@PADDING@@",
                "@@PADDING@@",
                "@@PADDING@@"
            ]
        },
        "token_indexers": {
            "elmo": {
                "type": "elmo_characters"
            }
        }
    },
    "train_data_path": "../data/train/train_placeholder",
    "validation_data_path": "../data/dev/dev_placeholder",
    "model": {
        "type": "sentence_classifier",
        "text_field_embedder": {
            "elmo": {
                "type": "elmo_token_embedder",
                "options_file": "../data/vectors/elmo_2x4096_512_2048cnn_2xhighway_options.json",
                "weight_file": "../data/vectors/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5",
                "do_layer_norm": false,
                "dropout": 0.5
            }
        },
        "question_encoder": {
            "type": "gru",
            "bidirectional": true,
            "num_layers": 1,
            "dropout": 0.5,
            "hidden_size": 256,
            "input_size": 1024
        }
    },
    "iterator": {
        "type": "bucket",
        "sorting_keys": [
            [
                "question",
                "num_tokens"
            ]
        ],
        "batch_size": 64
    },
    "trainer": {
        "num_epochs": 40,
        "patience": 10,
        "cuda_device": 0,
        "grad_clipping": 5.0,
        "validation_metric": "+accuracy",
        "learning_rate_scheduler": {
            "type": "reduce_on_plateau",
            "factor": 0.5,
            "mode": "max",
            "patience": 2
        },
        "optimizer": {
            "type": "adagrad"
        }
    }
}
